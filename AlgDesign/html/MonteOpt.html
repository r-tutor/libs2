<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Optimal design via Monte Carlo</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for optMonteCarlo {AlgDesign}"><tr><td>optMonteCarlo {AlgDesign}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Optimal design via Monte Carlo</h2>

<h3>Description</h3>

<p>Finds a design using the specified criterion via Federov's algorithm
applied to a random subset of all possible candidate points. 
</p>


<h3>Usage</h3>

<pre>
optMonteCarlo(frml,data,nTrials,approximate=FALSE,criterion="D",evaluateI=FALSE,
	space=NULL,mixtureSum=1,constraints=NULL,RandomStart=TRUE,nRepeats=5,nCand,
	nCandNull,DFrac=1,CFrac=1,args=FALSE)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>frml</code></td>
<td>
<p>Required: A formula starting with ~ which will be used with 
model.matrix() to create a model matrix. If there are mixture variables,
the constant term is suppressed.</p>
</td></tr>
<tr valign="top"><td><code>data</code></td>
<td>
<p>Required: A data frame with 7 or 8 columns. See details below
for specifics</p>
</td></tr> 
<tr valign="top"><td><code>nTrials</code></td>
<td>
<p>number trials in design &ndash; must be greater than the
number of terms in the model, if  missing will be set to the
number of model terms in the model  plus five.</p>
</td></tr>
<tr valign="top"><td><code>approximate</code></td>
<td>
<p>When FALSE, an exact design in nTrails will be calculated. When TRUE the proportions for
an approximate theory design will be calculated. If nTrials is set, any proportion less than 1/(2*maxIteration)
will be discarded before the proportions are efficiently rounded, otherwise all non-zero proportions will be 
shown: these are the support points.</p>
</td></tr>
<tr valign="top"><td><code>criterion</code></td>
<td>
<p>&quot;D&quot;, &quot;A&quot;, or &quot;I&quot;</p>
</td></tr>
<tr valign="top"><td><code>evaluateI</code></td>
<td>
<p>TRUE if I is to be evaluated in addition to the
other criteria &ndash; slower because of calculations for I</p>
</td></tr>
<tr valign="top"><td><code>space</code></td>
<td>
<p>If the criterion is &quot;I&quot; or evaluate I is true, the space over which the I criterion is to
be evaluated may be input. It should be a matrix with the same column types and names as in data. If
space is not input the evaluation will be done over the space described by data.</p>
</td></tr>	
<tr valign="top"><td><code>constraints</code></td>
<td>
<p>A function taking a vector argument with length
equal to the number of variables, and returning TRUE if the vector is 
inside the constrained region</p>
</td></tr>
<tr valign="top"><td><code>mixtureSum</code></td>
<td>
<p>The mixture variables, if any, will sum to this value.</p>
</td></tr>
<tr valign="top"><td><code>RandomStart</code></td>
<td>
<p>When TRUE, the starting design will be chosen
at random, otherwise nullification will be used. Note: the nullifcation
used here is different and much slower than that in optFederov().</p>
</td></tr>
<tr valign="top"><td><code>nRepeats</code></td>
<td>
<p>number of times to retry the entire process</p>
</td></tr>
<tr valign="top"><td><code>nCand</code></td>
<td>
<p>number of candidate points to generate, if missing,
it will be 10 times the number of terms</p>
</td></tr>
<tr valign="top"><td><code>nCandNull</code></td>
<td>
<p>Number of candidate points to use for
nullification. If missing it will be set to nCand</p>
</td></tr>
<tr valign="top"><td><code>DFrac</code></td>
<td>
<p>Fraction of design used in search: 1 uses all of
them, 0 only the one with the smallest variance</p>
</td></tr>
<tr valign="top"><td><code>CFrac</code></td>
<td>
<p>Fraction of candidate set searched : 1 uses all of
them, 0 only the one with the largest variance</p>
</td></tr>
<tr valign="top"><td><code>args</code></td>
<td>
<p>If TRUE, the actual arguments to the function including the starting 
random number seed will be output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The columns of the input data frame are as follows. The columns need
not be named. It is probably best to avoid naming the variables with
single letters, especially &quot;I&quot; &ndash; use paste(), as in the examples. For each variable
nLevels are randomly generated between low and high, inclusive, and then rounded
with round. For integer levels, round should be set to 0.
</p>

<dl>
<dt>var:</dt><dd><p>The names of the variables.</p>
</dd>
<dt>low:</dt><dd><p>The lower limit of the range for each variable. Ignored for mixtures.</p>
</dd> 
<dt>high:</dt><dd><p>The upper limit of the range for each variable. Ignored for mixtures.</p>
</dd> 
<dt>center:</dt><dd><p>The centering value for each variable. Ignored for mixtures.</p>
</dd>
<dt>nLevels:</dt><dd><p>The number of levels for each variable. Ignored for mixture variables.</p>
</dd>
<dt>round:</dt><dd><p>The number of decimal digits for the levels. The levels are randomly and 
uniformly chosen between low and high, and this parameter controls the number of 
trailing digits. The max value for mixture variables in this vector is used to 
round all mixture variables.</p>
</dd>
<dt>factor:</dt><dd><p>TRUE, FALSE depending on whether or not the variable is a factor. Note: other
columns will be reset to conform to a nLevels factor.</p>
</dd>
<dt>mix:</dt><dd><p>TRUE if the variable is a mixture variable. This column may
be omitted if there are no mixture variables.</p>
</dd>
</dl>

<p>Candidate lists required by <code>optFederov()</code> increase with the number of
variables, and can easily exceed storage capacity and can require
excessive amounts of time to process. To overcome this problem,
<code>optMonteCarlo()</code>, generates at random  <code>nCand</code>  points from a putative 
candidate list.
</p>
<p>For non-mixture variables, <code>optMonteCarlo()</code> samples from the putative
candidate list by choosing random levels inside the limits given by
<code>low</code> and <code>high</code> in <code>data</code>. These are rounded to the 
number of levels given by <code>nLevels</code> in <code>data</code> and to the 
number of decimal digits given by <code>round</code> in <code>data</code>.
</p>
<p>For mixture variables, <code>optMonteCarlo()</code> samples from the putative
candidate list by choosing random levels between 0 and 1, rounded to
the maximum in the <code>round</code> column of <code>data</code>, and such that the sum over 
all variables is equal to <code>mixtureSum</code>.
</p>
<p>If a constraint function is supplied in <code>Constraints</code>, it is
applied, and results which do not meet the constraint are
discarded. The constraint function should be written to process 
uncentered variables.
</p>
<p>The above procedures are repeated until <code>nCand</code> candidate points
are found.
</p>
<p>Nullification, successively adds points to a design until n points are 
found. This is the same procedure that is in <code>optFederov</code> except
that each new point is selected from a new sampling of the putative
candidate points. In general, this will produce better designs that
those from a random start.
</p>
<p>The entire process is repeated <code>nRepeats</code> times, and the best
result is reported. The methodology compares favorably with an
exhaustive search where the entire candidate list is searched by
<code>optFederov()</code>.
</p>
<p>The random numbers used in these calculations are controlled by the
usual R random number mechanism.
</p>
<p>A vignette giving further details is availble. To access it, type
</p>
<p>vignette(&quot;AlgDesign&quot;)
</p>


<h3>Value</h3>

<p>The output is the same list as from <code>optFederov</code>, but the criteria
values are relative to the randomly chosen subsets of the putative candidate 
space. In general, they should not differ greatly from those obtained by an 
exhaustive search.
</p>
<table summary="R valueblock">
<tr valign="top"><td><code>D</code></td>
<td>
<p>The kth root of the generalized variance: <i>det(M)^(1/k)</i>, where <i>det(M)</i> is the
determinant of the normalized dispersion matrix <i>M</i> &ndash;
i.e. <i>M=Z'Z/n</i>, where <i>Z=X[rows,]</i></p>
</td></tr>
<tr valign="top"><td><code>A</code></td>
<td>
<p>The average coefficient variance: <i>trace(Mi)/k</i>, where <i>Mi</i> is the inverse of <i>M</i>.</p>
</td></tr>
<tr valign="top"><td><code>I</code></td>
<td>
<p>The average prediction variance over X, which can be shown to be <i>trace((X'X*Mi)/N)</i>. 
This is calculated only when I is the criterion or when <code>evaluateI</code> is TRUE.</p>
</td></tr>
<tr valign="top"><td><code>Ge</code></td>
<td>
<p>The minimax normalized variance over X, expressed as an efficiency with respect to the optimal approximate
theory design. It is defined as <i>k/max(d)</i>, where <i>max(d)</i> is the maximum normalized
variance over <i>X</i> &ndash; i.e. the max of <i>x'(Mi)x</i>, over all rows <i>x'</i>
of <i>X</i>.</p>
</td></tr>
<tr valign="top"><td><code>Dea</code></td>
<td>
<p>A lower bound on <code>D</code> efficiency for approximate theory designs. It is equal to <i>exp(1-1/Ge)</i>.</p>
</td></tr>
<tr valign="top"><td><code>Design</code></td>
<td>
<p>The design.</p>
</td></tr> 
<tr valign="top"><td><code>args</code></td>
<td>
<p>A list of the actual arguments used in this call.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Bob Wheeler <a href="mailto:bwheelerg@gmail.com">bwheelerg@gmail.com</a>
</p>
<p>Please cite this program as follows:
</p>
<p>Wheeler, R.E. (2004). optMonteCarlo. <em>AlgDesign</em>. The R project for statistical computing <a href="https://www.r-project.org/">https://www.r-project.org/</a>
</p>


<h3>Examples</h3>

<pre>

# EXAMPLE 1
# The data.frame in data might look like the following:
data&lt;-data.frame(var=paste("X",1:6,sep=""),low=c(1,1,1,0,0,0),
high=c(3,3,3,1,1,1),center=c(2,2,2,0,0,0),nLevels=3,
round=1,factor=0,mix=c(FALSE,FALSE,FALSE,TRUE,TRUE,TRUE))
data

# and the design:

optMonteCarlo(~(X1+X2+X3)^2+X4+X5+X6,data)

# Example 2
# Standard designs will often be produced, just as 
# they will with optFederov(). For example,
# a half fraction of a 2^4:
data&lt;-data.frame(paste("X",1:4,sep=""),-1,1,0,2,0,0)
data
optMonteCarlo(~.,data,nTrials=8)

# Example 3
# optMonteCarlo() can treat much larger problems than can 
# optFederov().  For example, optFederov()
# requires a candidate list of 3^20 points for
# a 20 variable, 3 level candidate list -- about
# 25 gigabytes. If the model is quadratic, this must
# be multiplied by about 12. There are other storage
# requirements internal to optFederov() which easily
# double this value. optMonteCarlo() since it only samples
# from the putative candidate list, has no difficulty 
# with a problem of this size. The criterion values
# appearing in the output of optMonteCarlo() are based on
# these samples, but their values seem to be reasonable
# correct, as the following shows: (These are commented
# out for those who have a slow machine.)

dat&lt;-gen.factorial(levels=3,nVar=8)
#desF&lt;-optFederov(~quad(.),dat,eval=TRUE)
#desF[1:5]

data&lt;-data.frame(paste("X",1:8,sep=""),-1,1,0,3,0,0)
#desH&lt;-optMonteCarlo(~quad(.),data,Rand=FALSE,eval=TRUE)
#desH[1:5]

# The following is a 20 variable quadratic. Uncomment
# and wait a while, even if you have a fast machine.
# Note: nRepeats has been changed from its default.
# Note: criterion values for exact designs are often
# far from approximate theory optima; hence, Ge and De
# will be small.

data&lt;-data.frame(paste("X",1:20,sep=""),-1,1,0,3,0,0)
#desBig&lt;-optMonteCarlo(~quad(.),data,nRepeats=1)

# The following will produce improved criterion values

#desNBig&lt;-optMonteCarlo(~quad(.),data,Rand=FALSE,nRepeats=1)

# EXAMPLE 4
# Practically infeasible combinations of variable are 
# common. Designs may be produced which avoid such
# combinations by using a constraint function. Suppose,
# for example that one corner of a cubic box is not
# feasible, then the following will produce a design
# that makes no use of this corner.

Constraints&lt;-function(x){!(x[1]&gt;0.75 &amp;&amp; x[2]&gt;0.75)}
data&lt;-data.frame(paste("X",1:4,sep=""),-1,1,0,3,0,0)
desC&lt;-optMonteCarlo(~.,data,con=Constraints)

# The above just removes a corner. Increasing the
# number of levels will remove points along the
# boundary.

data&lt;-data.frame(paste("X",1:4,sep=""),-1,1,0,11,3,0)
desC2&lt;-optMonteCarlo(~.,data,con=Constraints)

</pre>

<hr /><div style="text-align: center;">[Package <em>AlgDesign</em> version 1.1-7.3.1 <a href="00Index.html">Index</a>]</div>
</body></html>
