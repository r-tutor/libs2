<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Cluster validation statistics (version for use with...</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for cqcluster.stats {fpc}"><tr><td>cqcluster.stats {fpc}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Cluster validation statistics (version for use with clusterbenchstats</h2>

<h3>Description</h3>

<p>This is a more sophisticated version of <code><a href="cluster.stats.html">cluster.stats</a></code>
for use with <code><a href="clusterbenchstats.html">clusterbenchstats</a></code>, see Hennig (2017).
Computes a number of distance-based statistics, which can be used for cluster
validation, comparison between clusterings and decision about
the number of clusters: cluster sizes, cluster diameters,
average distances within and between clusters, cluster separation,
biggest within cluster gap, 
average silhouette widths, the Calinski and Harabasz index,
a Pearson version of
Hubert's gamma coefficient, the Dunn index, further statistics
introduced
in Hennig (2017) and two indexes
to assess the similarity of two clusterings, namely the corrected Rand
index and Meila's VI.
</p>


<h3>Usage</h3>

<pre>
cqcluster.stats(d = NULL, clustering, alt.clustering = NULL,
                             noisecluster = FALSE, 
    silhouette = TRUE, G2 = FALSE, G3 = FALSE, wgap = TRUE, sepindex = TRUE, 
    sepprob = 0.1, sepwithnoise = TRUE, compareonly = FALSE, 
    aggregateonly = FALSE, 
    averagegap=FALSE, pamcrit=TRUE,
    dquantile=0.1,
    nndist=TRUE, nnk=2, standardisation="max", sepall=TRUE, maxk=10,
    cvstan=sqrt(length(clustering)))

## S3 method for class 'cquality'
summary(object,stanbound=TRUE,largeisgood=TRUE, ...)

## S3 method for class 'summary.cquality'
print(x, ...)

			      
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>d</code></td>
<td>
<p>a distance object (as generated by <code>dist</code>) or a distance
matrix between cases.</p>
</td></tr>
<tr valign="top"><td><code>clustering</code></td>
<td>
<p>an integer vector of length of the number of cases,
which indicates a clustering. The clusters have to be numbered
from 1 to the number of clusters.</p>
</td></tr>
<tr valign="top"><td><code>alt.clustering</code></td>
<td>
<p>an integer vector such as for
<code>clustering</code>, indicating an alternative clustering. If provided, the
corrected Rand index and Meila's VI for <code>clustering</code>
vs. <code>alt.clustering</code> are computed.</p>
</td></tr>
<tr valign="top"><td><code>noisecluster</code></td>
<td>
<p>logical. If <code>TRUE</code>, it is assumed that the
largest cluster number in <code>clustering</code> denotes a 'noise
class', i.e. points that do not belong to any cluster. These points
are not taken into account for the computation of all functions of
within and between cluster distances including the validation
indexes.</p>
</td></tr> 
<tr valign="top"><td><code>silhouette</code></td>
<td>
<p>logical. If <code>TRUE</code>, the silhouette statistics
are computed, which requires package <code>cluster</code>.</p>
</td></tr>
<tr valign="top"><td><code>G2</code></td>
<td>
<p>logical. If <code>TRUE</code>, Goodman and Kruskal's index G2
(cf. Gordon (1999), p. 62) is computed. This executes lots of
sorting algorithms and can be very slow (it has been improved
by R. Francois - thanks!)</p>
</td></tr>
<tr valign="top"><td><code>G3</code></td>
<td>
<p>logical. If <code>TRUE</code>, the index G3
(cf. Gordon (1999), p. 62) is computed. This executes <code>sort</code>
on all distances and can be extremely slow.</p>
</td></tr>
<tr valign="top"><td><code>wgap</code></td>
<td>
<p>logical. If <code>TRUE</code>, the widest within-cluster gaps
(largest link in within-cluster minimum spanning tree) are
computed. This is used for finding a good number of clusters in
Hennig (2013). See also parameter <code>averagegap</code>.</p>
</td></tr>
<tr valign="top"><td><code>sepindex</code></td>
<td>
<p>logical. If <code>TRUE</code>, a separation index is
computed, defined based on the distances for every point to the
closest point not in the same cluster. The separation index is then
the mean of the smallest proportion <code>sepprob</code> of these. This
allows to formalise separation less sensitive to a single or a few
ambiguous points. The output component corresponding to this is
<code>sindex</code>, not <code>separation</code>! This is used for finding a
good number of clusters in Hennig (2013). See also parameter
<code>sepall</code>.</p>
</td></tr>
<tr valign="top"><td><code>sepprob</code></td>
<td>
<p>numerical between 0 and 1, see <code>sepindex</code>.</p>
</td></tr>
<tr valign="top"><td><code>sepwithnoise</code></td>
<td>
<p>logical. If <code>TRUE</code> and <code>sepindex</code> and
<code>noisecluster</code> are both <code>TRUE</code>, the noise points are
incorporated as cluster in the separation index (<code>sepindex</code>)
computation. Also
they are taken into account for the computation for the minimum
cluster separation.</p>
</td></tr> 
<tr valign="top"><td><code>compareonly</code></td>
<td>
<p>logical. If <code>TRUE</code>, only the corrected Rand index
and Meila's VI are
computed and given out (this requires <code>alt.clustering</code> to be
specified).</p>
</td></tr>
<tr valign="top"><td><code>aggregateonly</code></td>
<td>
<p>logical. If <code>TRUE</code> (and not
<code>compareonly</code>), no clusterwise but only aggregated information
is given out (this cuts the size of the output down a bit).</p>
</td></tr>
<tr valign="top"><td><code>averagegap</code></td>
<td>
<p>logical. If <code>TRUE</code>, the average of the widest
within-cluster gaps over all clusters is given out; if
<code>FALSE</code>, the maximum is given out.</p>
</td></tr>
<tr valign="top"><td><code>pamcrit</code></td>
<td>
<p>logical. If <code>TRUE</code>, the average distance of points
to their respective cluster centroids is computed (criterion of the
PAM clustering method); centroids are chosen so that they minimise
this criterion for the given clustering.</p>
</td></tr>
<tr valign="top"><td><code>dquantile</code></td>
<td>
<p>numerical between 0 and 1; quantile used for kernel
density estimator for density indexes, see Hennig (2017), Sec. 3.6.</p>
</td></tr>
<tr valign="top"><td><code>nndist</code></td>
<td>
<p>logical. If <code>TRUE</code>, average distance to <code>nnk</code>th
nearest neighbour within cluster is computed.</p>
</td></tr>
<tr valign="top"><td><code>nnk</code></td>
<td>
<p>integer. Number of neighbours used in average and
coefficient of
variation of distance to nearest within cluster neighbour (clusters
with <code>nnk</code> or fewer points are ignored for this).</p>
</td></tr>
<tr valign="top"><td><code>standardisation</code></td>
<td>
<p><code>"none"</code>, <code>"max"</code>, <code>"ave"</code>,
<code>"q90"</code>, or a number. See details.</p>
</td></tr>
<tr valign="top"><td><code>sepall</code></td>
<td>
<p>logical. If <code>TRUE</code>, a fraction of smallest
<code>sepprob</code> distances to other clusters is used from every
cluster. Otherwise, a fraction of smallest <code>sepprob</code> distances
overall is used in the computation of <code>sindex</code>.</p>
</td></tr>
<tr valign="top"><td><code>maxk</code></td>
<td>
<p>numeric. Parsimony is defined as the number of clusters
divided by <code>maxk</code>.</p>
</td></tr>
<tr valign="top"><td><code>cvstan</code></td>
<td>
<p>numeric. <code>cvnnd</code> is standardised by <code>cvstan</code>
if there is standardisation, see Details.</p>
</td></tr>
<tr valign="top"><td><code>object</code></td>
<td>
<p>object of class <code>cquality</code>, output of <code>cqcluster.stats</code>.</p>
</td></tr>
<tr valign="top"><td><code>x</code></td>
<td>
<p>object of class <code>cquality</code>, output of <code>cqcluster.stats</code>.</p>
</td></tr>
<tr valign="top"><td><code>stanbound</code></td>
<td>
<p>logical. If <code>TRUE</code>, all index values larger than
1 will be set to 1, and all values smaller than 0 will be set to 0.
This is for preparation in case of <code>largeisgood=TRUE</code> (if
values are already suitably standardised within
<code>cqcluster.stats</code>, it won't do harm and can do good).</p>
</td></tr>
<tr valign="top"><td><code>largeisgood</code></td>
<td>
<p>logical. If <code>TRUE</code>, indexes <code>x</code> are
transformed to <code>1-x</code> in case that before transformation smaller
values indicate a better clustering (that's <code>average.within,
      mnnd, widestgap, within.cluster.ss, dindex, denscut, pamc,
      max.diameter, highdgap, cvnnd</code>. For this to make sense,
<code>cqcluster.stats</code> should be run with
<code>standardisation="max"</code> and <code>summary.cquality</code> with
<code>stanbound=TRUE</code>.</p>
</td></tr> 
<tr valign="top"><td><code>...</code></td>
<td>
<p>no effect.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>standardisation</code>-parameter governs the standardisation of
the index values.
<code>standardisation="none"</code> means that unstandardised
raw values of indexes are given out. Otherwise, <code>entropy</code> will be
standardised by the
maximum possible value for the given number of clusters;
<code>within.cluster.ss</code> and <code>between.cluster.ss</code> will be
standardised by the overall sum of squares; <code>mnnd</code> will be
standardised by the maximum distance to the <code>nnk</code>th nearest
neighbour within cluster; <code>pearsongamma</code> will be standardised
by adding 1 and dividing by 2; <code>cvnn</code> will be standardised by
<code>cvstan</code> (the default is the possible maximum).
</p>
<p><code>standardisation</code> allows options for the standardisation of
<code>average.within, sindex, wgap, pamcrit, max.diameter,
  min.separation</code> and can be <code>"max"</code> (maximum distance),
<code>"ave"</code> (average distance), <code>q90</code> (0.9-quantile of
distances), or a positive number. <code>"max"</code> is the default and
standardises all the listed indexes into the range [0,1].</p>


<h3>Value</h3>

<p><code>cqcluster.stats</code> with <code>compareonly=FALSE</code> and
<code>aggregateonly=FALSE</code> returns a list of type
<code>cquality</code> containing the components
<code>n, cluster.number, cluster.size,  min.cluster.size, noisen,
    diameter,
    average.distance, median.distance, separation, average.toother,
    separation.matrix, ave.between.matrix, average.between, average.within,
    n.between, n.within, max.diameter, min.separation,
    within.cluster.ss, clus.avg.silwidths, avg.silwidth,
    g2, g3, pearsongamma, dunn, dunn2, entropy, wb.ratio, ch, cwidegap,
    widestgap, corrected.rand, vi, sindex, svec, psep, stan, nnk, mnnd,
    pamc, pamcentroids, dindex, denscut, highdgap, npenalty, dpenalty,
    withindensp, densoc, pdistto, pclosetomode, distto, percwdens,
    percdensoc, parsimony, cvnnd, cvnndc</code>. Some of these are
standardised, see Details. If
<code>compareonly=TRUE</code>, only <code>corrected.rand, vi</code> are given
out. If <code>aggregateonly=TRUE</code>, only <code>n, cluster.number,
    min.cluster.size, noisen, diameter,
    average.between, average.within,
    max.diameter, min.separation,
    within.cluster.ss, avg.silwidth,
    g2, g3, pearsongamma, dunn, dunn2, entropy, wb.ratio, ch, 
    widestgap, corrected.rand, vi, sindex, svec, psep, stan, nnk, mnnd,
    pamc, pamcentroids, dindex, denscut, highdgap, parsimony, cvnnd,
    cvnndc</code> are given out.
</p>
<p><code>summary.cquality</code> returns a list of type <code>summary.cquality</code>
with components <code>average.within,nnk,mnnd,
              avg.silwidth,
              widestgap,sindex,
              pearsongamma,entropy,pamc,
              within.cluster.ss,
              dindex,denscut,highdgap,
              parsimony,max.diameter,
              min.separation,cvnnd</code>. These are as documented below for
<code>cqcluster.stats</code>, but after transformation by <code>stanbound</code>
and <code>largeisgood</code>, see arguments.
</p>
<table summary="R valueblock">
<tr valign="top"><td><code>n</code></td>
<td>
<p>number of points.</p>
</td></tr>
<tr valign="top"><td><code>cluster.number</code></td>
<td>
<p>number of clusters.</p>
</td></tr>
<tr valign="top"><td><code>cluster.size</code></td>
<td>
<p>vector of cluster sizes (number of points).</p>
</td></tr>
<tr valign="top"><td><code>min.cluster.size</code></td>
<td>
<p>size of smallest cluster.</p>
</td></tr>
<tr valign="top"><td><code>noisen</code></td>
<td>
<p>number of noise points, see argument <code>noisecluster</code>
(<code>noisen=0</code> if <code>noisecluster=FALSE</code>).</p>
</td></tr>
<tr valign="top"><td><code>diameter</code></td>
<td>
<p>vector of cluster diameters (maximum within cluster
distances).</p>
</td></tr>
<tr valign="top"><td><code>average.distance</code></td>
<td>
<p>vector of clusterwise
within cluster average distances.</p>
</td></tr>
<tr valign="top"><td><code>median.distance</code></td>
<td>
<p>vector of clusterwise
within cluster distance medians.</p>
</td></tr>
<tr valign="top"><td><code>separation</code></td>
<td>
<p>vector of clusterwise minimum distances of a point
in the cluster to a point of another cluster.</p>
</td></tr>
<tr valign="top"><td><code>average.toother</code></td>
<td>
<p>vector of clusterwise average distances of a point
in the cluster to the points of other clusters.</p>
</td></tr>
<tr valign="top"><td><code>separation.matrix</code></td>
<td>
<p>matrix of separation values between all pairs
of clusters.</p>
</td></tr>
<tr valign="top"><td><code>ave.between.matrix</code></td>
<td>
<p>matrix of mean dissimilarities between
points of every pair of clusters.</p>
</td></tr>
<tr valign="top"><td><code>avebetween</code></td>
<td>
<p>average distance between clusters.</p>
</td></tr>
<tr valign="top"><td><code>avewithin</code></td>
<td>
<p>average distance within clusters (reweighted so
that every observation, rather than every distance, has the same weight).</p>
</td></tr>
<tr valign="top"><td><code>n.between</code></td>
<td>
<p>number of distances between clusters.</p>
</td></tr>
<tr valign="top"><td><code>n.within</code></td>
<td>
<p>number of distances within clusters.</p>
</td></tr>
<tr valign="top"><td><code>maxdiameter</code></td>
<td>
<p>maximum cluster diameter.</p>
</td></tr>
<tr valign="top"><td><code>minsep</code></td>
<td>
<p>minimum cluster separation.</p>
</td></tr>
<tr valign="top"><td><code>withinss</code></td>
<td>
<p>a generalisation of the within clusters sum
of squares (k-means objective function), which is obtained if
<code>d</code> is a Euclidean distance matrix.  For general distance
measures, this is half
the sum of the within cluster squared dissimilarities divided by the
cluster size.</p>
</td></tr>
<tr valign="top"><td><code>clus.avg.silwidths</code></td>
<td>
<p>vector of cluster average silhouette
widths. See
<code><a href="../../cluster/html/silhouette.html">silhouette</a></code>.</p>
</td></tr>
<tr valign="top"><td><code>asw</code></td>
<td>
<p>average silhouette
width. See <code><a href="../../cluster/html/silhouette.html">silhouette</a></code>.</p>
</td></tr>
<tr valign="top"><td><code>g2</code></td>
<td>
<p>Goodman and Kruskal's Gamma coefficient. See Milligan and
Cooper (1985), Gordon (1999, p. 62).</p>
</td></tr>
<tr valign="top"><td><code>g3</code></td>
<td>
<p>G3 coefficient. See Gordon (1999, p. 62).</p>
</td></tr>
<tr valign="top"><td><code>pearsongamma</code></td>
<td>
<p>correlation between distances and a
0-1-vector where 0 means same cluster, 1 means different clusters.
&quot;Normalized gamma&quot; in Halkidi et al. (2001).</p>
</td></tr>
<tr valign="top"><td><code>dunn</code></td>
<td>
<p>minimum separation / maximum diameter. Dunn index, see
Halkidi et al. (2002).</p>
</td></tr>
<tr valign="top"><td><code>dunn2</code></td>
<td>
<p>minimum average dissimilarity between two cluster /
maximum average within cluster dissimilarity, another version of
the family of Dunn indexes.</p>
</td></tr> 
<tr valign="top"><td><code>entropy</code></td>
<td>
<p>entropy of the distribution of cluster memberships,
see Meila(2007).</p>
</td></tr>
<tr valign="top"><td><code>wb.ratio</code></td>
<td>
<p><code>average.within/average.between</code>.</p>
</td></tr>
<tr valign="top"><td><code>ch</code></td>
<td>
<p>Calinski and Harabasz index (Calinski and Harabasz 1974,
optimal in Milligan and Cooper 1985; generalised for dissimilarites
in Hennig and Liao 2013).</p>
</td></tr>
<tr valign="top"><td><code>cwidegap</code></td>
<td>
<p>vector of widest within-cluster gaps.</p>
</td></tr>
<tr valign="top"><td><code>widestgap</code></td>
<td>
<p>widest within-cluster gap or average of cluster-wise
widest within-cluster gap, depending on parameter <code>averagegap</code>.</p>
</td></tr>
<tr valign="top"><td><code>corrected.rand</code></td>
<td>
<p>corrected Rand index (if <code>alt.clustering</code>
has been specified), see Gordon (1999, p. 198).</p>
</td></tr>
<tr valign="top"><td><code>vi</code></td>
<td>
<p>variation of information (VI) index (if <code>alt.clustering</code>
has been specified), see Meila (2007).</p>
</td></tr>
<tr valign="top"><td><code>sindex</code></td>
<td>
<p>separation index, see argument <code>sepindex</code>.</p>
</td></tr>
<tr valign="top"><td><code>svec</code></td>
<td>
<p>vector of smallest closest distances of points to next
cluster that are used in the computation of <code>sindex</code> if
<code>sepall=TRUE</code>.</p>
</td></tr>
<tr valign="top"><td><code>psep</code></td>
<td>
<p>vector of all closest distances of points to next
cluster.</p>
</td></tr>
<tr valign="top"><td><code>stan</code></td>
<td>
<p>value by which som statistics were standardised, see
Details.</p>
</td></tr>
<tr valign="top"><td><code>nnk</code></td>
<td>
<p>value of input parameter <code>nnk</code>.</p>
</td></tr>
<tr valign="top"><td><code>mnnd</code></td>
<td>
<p>average distance to <code>nnk</code>th nearest neighbour within
cluster.</p>
</td></tr>
<tr valign="top"><td><code>pamc</code></td>
<td>
<p>average distance to cluster centroid.</p>
</td></tr>
<tr valign="top"><td><code>pamcentroids</code></td>
<td>
<p>index numbers of cluster centroids.</p>
</td></tr>
<tr valign="top"><td><code>dindex</code></td>
<td>
<p>this index measures to what extent the density decreases
from the cluster mode to the outskirts; I-densdec in Sec. 3.6 of
Hennig (2017); low values are good.</p>
</td></tr>
<tr valign="top"><td><code>denscut</code></td>
<td>
<p>this index measures whether cluster boundaries run
through density valleys; I-densbound in Sec. 3.6 of Hennig (2017); low
values are good.</p>
</td></tr>
<tr valign="top"><td><code>highdgap</code></td>
<td>
<p>this measures whether there is a large within-cluster
gap with high density on both sides; I-highdgap in Sec. 3.6 of
Hennig (2017); low values are good.</p>
</td></tr>
<tr valign="top"><td><code>npenalty</code></td>
<td>
<p>vector of penalties for all clusters that are used
in the computation of <code>denscut</code>, see Hennig (2017) (these are
sums of penalties over all points in the cluster).</p>
</td></tr>
<tr valign="top"><td><code>depenalty</code></td>
<td>
<p>vector of penalties for all clusters that are used in
the computation of <code>dindex</code>, see Hennig (2017) (these are
sums of several penalties for density increase when going from the
mode outward in the cluster).</p>
</td></tr>
<tr valign="top"><td><code>withindensp</code></td>
<td>
<p>distance-based kernel density values for all points
as computed in Sec. 3.6 of Hennig (2017).</p>
</td></tr>
<tr valign="top"><td><code>densoc</code></td>
<td>
<p>contribution of points from other clusters than the one
to which a point is assigned to the density, for all points; called
<code>h_o</code> in Sec. 3.6 of Hennig (2017).</p>
</td></tr>
<tr valign="top"><td><code>pdistto</code></td>
<td>
<p>list that for all clusters has a sequence of point
numbers. These are the points already incorporated in the sequence
of points constructed in the algorithm in Sec. 3.6 of Hennig (2017) to
which the next point to be joined is connected.</p>
</td></tr>
<tr valign="top"><td><code>pclosetomode</code></td>
<td>
<p>list that for all clusters has a sequence of point
numbers. Sequence of points to be incorporated in the sequence
of points constructed in the algorithm in Sec. 3.6 of Hennig
(2017).</p>
</td></tr>
<tr valign="top"><td><code>distto</code></td>
<td>
<p>list that for all clusters has a sequence of differences
between the standardised densities (see <code>percwdens</code>) at the new
point added and the point to which
it is connected (if this is positive, the penalty is this to the
square), in the algorithm in Sec. 3.6 of Hennig (2017).</p>
</td></tr>
<tr valign="top"><td><code>percwdens</code></td>
<td>
<p>this is <code>withindensp</code> divided by its maximum.</p>
</td></tr>
<tr valign="top"><td><code>percdensoc</code></td>
<td>
<p>this is <code>densoc</code> divided by the maximum of
<code>withindensp</code>, called <code>h_o^*</code> in Sec. 3.6 of Hennig (2017).</p>
</td></tr>
<tr valign="top"><td><code>parsimony</code></td>
<td>
<p>number of clusters divided by <code>maxk</code>.</p>
</td></tr>
<tr valign="top"><td><code>cvnnd</code></td>
<td>
<p>coefficient of variation of dissimilarities to
<code>nnk</code>th nearest within-cluster neighbour, measuring uniformity of
within-cluster densities, weighted over all clusters, see Sec. 3.7 of
Hennig (2017).</p>
</td></tr>
<tr valign="top"><td><code>cvnndc</code></td>
<td>
<p>vector of cluster-wise coefficients of variation of
dissimilarities to <code>nnk</code>th nearest wthin-cluster neighbour as
required in computation of <code>cvnnd</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Because <code>cqcluster.stats</code> processes a full dissimilarity matrix, it
isn't suitable for large data sets. You may consider
<code><a href="distcritmulti.html">distcritmulti</a></code> in that case.
</p>


<h3>Author(s)</h3>

<p>Christian Hennig
<a href="mailto:christian.hennig@unibo.it">christian.hennig@unibo.it</a>
<a href="https://www.unibo.it/sitoweb/christian.hennig/en/">https://www.unibo.it/sitoweb/christian.hennig/en/</a>
</p>


<h3>References</h3>

<p>Calinski, T., and Harabasz, J. (1974) A Dendrite Method for Cluster 
Analysis, <em>Communications in Statistics</em>, 3, 1-27.
</p>
<p>Gordon, A. D. (1999) <em>Classification</em>, 2nd ed. Chapman and Hall.
</p>
<p>Halkidi, M., Batistakis, Y., Vazirgiannis, M. (2001) On Clustering
Validation Techniques, <em>Journal of Intelligent Information
Systems</em>, 17, 107-145.
</p>
<p>Hennig, C. and Liao, T. (2013) How to find an appropriate clustering
for mixed-type variables with application to socio-economic
stratification, <em>Journal of the Royal Statistical Society, Series
C Applied Statistics</em>, 62, 309-369.
</p>
<p>Hennig, C. (2013) How many bee species? A case study in
determining the number of clusters. In: Spiliopoulou, L. Schmidt-Thieme,
R. Janning (eds.):
&quot;Data Analysis, Machine Learning and Knowledge Discovery&quot;, Springer,
Berlin, 41-49.
</p>
<p>Hennig, C. (2017) Cluster validation by measurement of clustering
characteristics relevant to the user. In C. H. Skiadas (ed.)
<em>Proceedings of ASMDA 2017</em>, 501-520,
<a href="https://arxiv.org/abs/1703.09282">https://arxiv.org/abs/1703.09282</a>
</p>
<p>Kaufman, L. and Rousseeuw, P.J. (1990). &quot;Finding Groups in Data:
An Introduction to Cluster Analysis&quot;. Wiley, New York.
</p>
<p>Meila, M. (2007) Comparing clusterings?an information based distance,
<em>Journal of Multivariate Analysis</em>, 98, 873-895.
</p>
<p>Milligan, G. W. and Cooper, M. C. (1985) An examination of procedures
for determining the number of clusters. <em>Psychometrika</em>, 50, 159-179.
</p>


<h3>See Also</h3>

<p><code><a href="cluster.stats.html">cluster.stats</a></code>,
<code><a href="../../cluster/html/silhouette.html">silhouette</a></code>, <code><a href="../../stats/html/dist.html">dist</a></code>, <code><a href="calinhara.html">calinhara</a></code>,
<code><a href="distcritmulti.html">distcritmulti</a></code>.
<code><a href="clusterboot.html">clusterboot</a></code> computes clusterwise stability statistics by
resampling.
</p>


<h3>Examples</h3>

<pre>  
  set.seed(20000)
  options(digits=3)
  face &lt;- rFace(200,dMoNo=2,dNoEy=0,p=2)
  dface &lt;- dist(face)
  complete3 &lt;- cutree(hclust(dface),3)
  cqcluster.stats(dface,complete3,
                alt.clustering=as.integer(attr(face,"grouping")))
  
</pre>

<hr /><div style="text-align: center;">[Package <em>fpc</em> version 2.2-2 <a href="00Index.html">Index</a>]</div>
</body></html>
